{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download dos casos de Malária\n",
    "\n",
    "#### Os casos de Malária foram baixados a partir do repositório do Sistema de Informação de Agravos de Notificação (SINAN),  que é alimentado, principalmente, pela notificação e investigação de casos de doenças e agravos que constam da lista nacional de doenças de notificação compulsória.  O downlod foi feito a partir do Package Python PySUS, criado para auxiliar no acesso e manipulação de base de dados publicadas pelo DATASUS.\n",
    "\n",
    "#### Maiores informações em:\n",
    "\n",
    " - [SINAN] (https://portalsinan.saude.gov.br/sinan-net)\n",
    " - [Malária] (https://portalsinan.saude.gov.br/malaria)\n",
    " - [PySUS] (https://pysus.readthedocs.io/en/latest/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 - Importando o método SINAN do pacote PySUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysus.ftp.databases.sinan import SINAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - Carregando os dados a partir do servidor do DataSUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinan = SINAN().load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - Lista os arquivos disponíveis para Malária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos = sinan.get_files(dis_code=[\"MALA\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 - Download dos arquivos disponíveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115k/115k [00:00<00:00, 65.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "parquets = sinan.download(arquivos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 - Converte os arquivos parquet em uma lista de dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [parquet.to_dataframe() for parquet in parquets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6 - Concatena em um único dataframe selecionando apenas as colunas de interesse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['DT_NOTIFIC', 'SEM_NOT', 'NU_ANO', 'ID_MUNICIP']\n",
    "selected_dfs = [df[selected_columns] for df in dataframes]\n",
    "df = pd.concat(selected_dfs, ignore_index=True, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7 - Corrige os tipos dos campos de data e numéricos, e decodifica e o campo da semana da notificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria a função convert_week para decodificar a coluna \"SEM_NOT\" \n",
    "def convert_week(x):\n",
    "        try:\n",
    "            w = int(x) % 100\n",
    "        except ValueError:\n",
    "            w = np.nan\n",
    "        return w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_738/711638361.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[cname].replace(\"\", np.nan, inplace=True)\n",
      "/tmp/ipykernel_738/711638361.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[cname].replace(\"\", np.nan, inplace=True)\n",
      "/tmp/ipykernel_738/711638361.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[cname].replace(\"\", np.nan, inplace=True)\n",
      "/tmp/ipykernel_738/711638361.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[cname].replace(\"\", np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "    for cname in df.columns:\n",
    "        df[cname].replace(\"\", np.nan, inplace=True)\n",
    "        if cname.startswith((\"NU\", \"ID\")):\n",
    "            try:\n",
    "                df[cname] = pd.to_numeric(df[cname])\n",
    "            except ValueError as e:\n",
    "                print(f\"Column {cname} could not be converted to numeric: {e}\")\n",
    "                # certain IDs can be alphanumerical\n",
    "                pass\n",
    "        elif cname.startswith(\"DT\"):\n",
    "            try:\n",
    "                df[cname] = pd.to_datetime(df[cname])\n",
    "            except ValueError as e:\n",
    "                print(f\"Column {cname} could not be converted to date: {e}\")\n",
    "        elif cname.startswith(\"SEM\"):\n",
    "            df[cname] = df[cname].map(convert_week)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8 - Agrupa e contando os registros por data e município"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df.groupby(['DT_NOTIFIC', 'SEM_NOT', 'NU_ANO', 'ID_MUNICIP']).size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9 - Ligação com a tabela de municípios importada com o pacote Geobr\n",
    "#### Até o ano de 2006, o código do município apresenta 7 dígitos, depois de 2006 o código do município apresenta 6 dígitos. Desta maneira o merge será dividido em duas etapas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geobr import read_municipality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mun = read_municipality(code_muni=\"all\", year=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte a coluna 'code_muni' de float para int em uma nova coluna 'ID_MUNICIP'\n",
    "mun['ID_MUNICIP_1'] = mun['code_muni'].astype('Int64')\n",
    "\n",
    "# Remover o último dígito da coluna 'ID_MUNICIP'\n",
    "mun['ID_MUNICIP_2'] = mun['ID_MUNICIP_1'].astype(str).str[:-1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "selecao_1 = (counts['DT_NOTIFIC'] >= '2004-01-01') & (counts['DT_NOTIFIC'] <= '2006-12-31')\n",
    "counts_1 = counts[selecao_1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "selecao_2 = (counts['DT_NOTIFIC'] >= '2007-01-01') & (counts['DT_NOTIFIC'] <= '2023-12-31')\n",
    "counts_2 = counts[selecao_2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Junção dos dataframes 'counts' e 'mun' mantendo todos os registros mesmo quando não houver correspondência\n",
    "merged_1 = counts_1.merge(mun, left_on='ID_MUNICIP', right_on='ID_MUNICIP_1', how='outer', indicator=True)\n",
    "merged_2 = counts_2.merge(mun, left_on='ID_MUNICIP', right_on='ID_MUNICIP_2', how='outer', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.concat([merged_1, merged_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10 - Exportando em CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordenando as colunas\n",
    "sinan_malaria_2004_2023 = merged[['DT_NOTIFIC', 'SEM_NOT', 'NU_ANO', 'code_muni', 'name_muni', 'abbrev_state', 'name_state', 'name_region', 'count', 'geometry']]\n",
    "\n",
    "# Renomeando as colunas\n",
    "sinan_malaria_2004_2023.columns = ['data', 'semana', 'ano','geocodigo', 'municipio',  'uf_sigla', 'uf', 'regiao', 'casos', 'geometry']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportando para CSV\n",
    "sinan_malaria_2004_2023.to_csv('sinan_malaria_2004_2023.csv',sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11 - Exportando em GeoJason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando geopandas\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo para GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(sinan_malaria_2004_2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportanod para GeoJSON\n",
    "gdf.to_file('sinan_malaria_2004_2023.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
